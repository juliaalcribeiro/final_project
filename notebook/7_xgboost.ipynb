{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5898d36-f4e4-4e80-b04b-8076f3b8ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š XGBoost Evaluation:\n",
      "  RMSE: 1.4823\n",
      "  MAE : 1.2494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "import yaml\n",
    "\n",
    "# 1. Carregar os dados (que jÃ¡ estÃ£o com One-Hot Encoding do notebook 1)\n",
    "with open(\"../config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "train_df = pd.read_csv(config['output_data']['train_file'])\n",
    "test_df = pd.read_csv(config['output_data']['test_file'])\n",
    "\n",
    "# 2. Separar Features (X) e Target (y)\n",
    "# Remover colunas de texto/descriÃ§Ã£o se houverem sobrado, manter apenas numÃ©ricas e one-hot\n",
    "features_to_drop = ['pairing_quality', 'quality_label', 'description'] \n",
    "# Nota: certifique-se de remover IDs brutos se for usar One-Hot, ou remover One-Hot se for usar IDs (CatBoost usa IDs bem).\n",
    "# Assumindo o uso do One-Hot gerado no notebook 1:\n",
    "\n",
    "X_train = train_df.drop(columns=features_to_drop, errors='ignore')\n",
    "y_train = train_df['pairing_quality']\n",
    "\n",
    "X_test = test_df.drop(columns=features_to_drop, errors='ignore')\n",
    "y_test = test_df['pairing_quality']\n",
    "\n",
    "# 3. Treinar XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=500,     # Mais Ã¡rvores\n",
    "    learning_rate=0.05,   # Aprendizado mais lento e preciso\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Prever e Avaliar\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"ðŸ“Š XGBoost Evaluation:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE : {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c117242-3e68-46f9-a263-667d945d28e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
