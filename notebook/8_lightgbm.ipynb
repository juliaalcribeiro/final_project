{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf02dd41-b02b-4345-89a5-76c60a0a8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 6588, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.505278\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 587\n",
      "[LightGBM] [Info] Number of data points in the train set: 6588, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.504396\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 6588, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.505411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 6588, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.504630\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 588\n",
      "[LightGBM] [Info] Number of data points in the train set: 6588, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.504472\n",
      "\n",
      "================ CV RESULTS ================\n",
      "RMSE: 0.2788401746877855\n",
      "MAE : 0.15964402828962201\n",
      "===========================================\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 590\n",
      "[LightGBM] [Info] Number of data points in the train set: 8235, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 0.504837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lgb_pairing_model.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Wine–Food Pairing - CV Evaluation (RMSE & MAE)\n",
    "# ======================================================\n",
    "\n",
    "import os, yaml\n",
    "import pandas as pd, numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Load configuration file and dataset\n",
    "# --------------------------------------------------------\n",
    "try:\n",
    "    with open(\"../config.yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except:\n",
    "    print(\"Yaml configuration file not found!\")\n",
    "\n",
    "df0 = pd.read_csv(config['input_data']['file'])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Define target & group columns\n",
    "# --------------------------------------------------------\n",
    "target_col = \"pairing_quality\"\n",
    "group_cols = [\n",
    "    c for c in [\"wine_type\", \"wine_category\", \"food_item\", \n",
    "                \"food_category\", \"cuisine\"] \n",
    "    if c in df0.columns\n",
    "]\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Aggregate duplicates and scale target\n",
    "# --------------------------------------------------------\n",
    "df = df0.groupby(group_cols)[target_col].mean().reset_index()\n",
    "\n",
    "min_r, max_r = df[target_col].min(), df[target_col].max()\n",
    "df[\"target_scaled\"] = (df[target_col] - min_r) / (max_r - min_r)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Feature Engineering (ID, target encoding, crosses)\n",
    "# --------------------------------------------------------\n",
    "cat_cols = group_cols.copy()\n",
    "\n",
    "# IDs\n",
    "for c in cat_cols:\n",
    "    df[c + \"_id\"] = pd.factorize(df[c])[0]\n",
    "\n",
    "# Target encoding\n",
    "for c in cat_cols:\n",
    "    te = df.groupby(c)[\"target_scaled\"].mean()\n",
    "    df[c + \"_te\"] = df[c].map(te)\n",
    "\n",
    "# Cross features\n",
    "def make_cross(a, b):\n",
    "    return pd.factorize(a.astype(str) + \"||\" + b.astype(str))[0]\n",
    "\n",
    "df[\"wine_cuisine_cross_id\"] = make_cross(df[\"wine_type\"], df[\"cuisine\"])\n",
    "\n",
    "df[\"wine_foodcat_cross_id\"] = make_cross(df[\"wine_type\"], df[\"food_category\"])\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5. Select features\n",
    "# --------------------------------------------------------\n",
    "feature_cols = []\n",
    "for c in cat_cols:\n",
    "    feature_cols += [c + \"_id\", c + \"_te\"]\n",
    "\n",
    "feature_cols += [c for c in [\"wine_cuisine_cross_id\", \"wine_foodcat_cross_id\"]]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"target_scaled\"].values\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 6. CV Evaluation (LightGBM)\n",
    "# --------------------------------------------------------\n",
    "def cv_quick(X, y, params, n_splits=5, n_estimators=200):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    rmses, maes = [], []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        Xtr, Xv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        ytr, yv = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params, n_estimators=n_estimators, random_state=0)\n",
    "        model.fit(Xtr, ytr)\n",
    "\n",
    "        p = model.predict(Xv)\n",
    "\n",
    "        # convert predictions back to original scale\n",
    "        p_orig = p * (max_r - min_r) + min_r\n",
    "        yv_orig = yv * (max_r - min_r) + min_r\n",
    "\n",
    "        rmses.append(np.sqrt(mean_squared_error(yv_orig, p_orig)))\n",
    "        maes.append(mean_absolute_error(yv_orig, p_orig))\n",
    "\n",
    "    return np.mean(rmses), np.mean(maes)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 7. Compute RMSE and MAE for a baseline model\n",
    "# --------------------------------------------------------\n",
    "params = {\"learning_rate\": 0.05, \"num_leaves\": 31}\n",
    "rmse, mae = cv_quick(X, y, params, n_splits=5, n_estimators=300)\n",
    "\n",
    "print(\"\\n================ CV RESULTS ================\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"===========================================\\n\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 8. Train FINAL model and save it as joblib\n",
    "# ======================================================\n",
    "\n",
    "final_model = LGBMRegressor(\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    n_estimators=300,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(final_model, \"lgb_pairing_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "198fe4d8-2a08-4158-9da0-7cce93b6aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Wine–Food Pairing - Recommendation System (Top 5)\n",
    "# ======================================================\n",
    "\n",
    "# ------------------------------\n",
    "# Load trained model\n",
    "# ------------------------------\n",
    "model = joblib.load(\"lgb_pairing_model.joblib\")\n",
    "\n",
    "# ======================================================\n",
    "# 1. Utility functions - Replicating Feature Engineering\n",
    "# ======================================================\n",
    "\n",
    "def factorize_and_map(df_full, df_query, col):\n",
    "    \"\"\"\n",
    "    Replicates factorize() used during training.\n",
    "    Ensures query values receive consistent IDs.\n",
    "    Unknown values -> -1.\n",
    "    \"\"\"\n",
    "    _, uniques = pd.factorize(df_full[col])\n",
    "    mapping = {v: i for i, v in enumerate(uniques)}\n",
    "    return df_query[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "\n",
    "def target_encode(df_full, df_query, col):\n",
    "    \"\"\"\n",
    "    Target encoding (mean of target_scaled grouped by column).\n",
    "    Unknown values -> global mean.\n",
    "    \"\"\"\n",
    "    te_map = df_full.groupby(col)[\"target_scaled\"].mean()\n",
    "    global_mean = df_full[\"target_scaled\"].mean()\n",
    "    return df_query[col].map(te_map).fillna(global_mean)\n",
    "\n",
    "\n",
    "def make_cross_for_query(df_full, df_query, colA, colB, new_col_name):\n",
    "    \"\"\"\n",
    "    Generates cross-feature IDs exactly like during training.\n",
    "    Unseen combinations -> -1.\n",
    "    \"\"\"\n",
    "    full_cross = (df_full[colA].astype(str) + \"||\" + df_full[colB].astype(str))\n",
    "    _, uniques = pd.factorize(full_cross)\n",
    "    map_cross = {v: i for i, v in enumerate(uniques)}\n",
    "\n",
    "    query_cross = (df_query[colA].astype(str) + \"||\" + df_query[colB].astype(str))\n",
    "    df_query[new_col_name] = query_cross.map(map_cross).fillna(-1).astype(int)\n",
    "    return df_query\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. Recommendation Function\n",
    "# ======================================================\n",
    "\n",
    "def recommend_wines(food_item, food_category, cuisine, preferred_wine_category=None):\n",
    "    \"\"\"\n",
    "    Returns the Top-5 wine recommendations for a given food combination.\n",
    "    Uses known dataset scores when available, otherwise model predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 1: Build wine candidates\n",
    "    # ----------------------------------------------\n",
    "    wine_df = df.copy()\n",
    "    wine_df = wine_df[[\"wine_type\", \"wine_category\"]].drop_duplicates()\n",
    "\n",
    "    # Optional user preference filter\n",
    "    if preferred_wine_category is not None:\n",
    "        wine_df = wine_df[wine_df[\"wine_category\"] == preferred_wine_category]\n",
    "\n",
    "    if wine_df.empty:\n",
    "        raise ValueError(\"No wines found for the given preferred wine_category.\")\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 2: Build query dataframe\n",
    "    # ----------------------------------------------\n",
    "    q = wine_df.copy()\n",
    "    q[\"food_item\"] = food_item\n",
    "    q[\"food_category\"] = food_category\n",
    "    q[\"cuisine\"] = cuisine\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 3: Reapply feature engineering\n",
    "    # ----------------------------------------------\n",
    "    for c in cat_cols:\n",
    "        q[c + \"_id\"] = factorize_and_map(df, q, c)\n",
    "\n",
    "    for c in cat_cols:\n",
    "        q[c + \"_te\"] = target_encode(df, q, c)\n",
    "\n",
    "    if \"wine_type\" in df.columns and \"cuisine\" in df.columns:\n",
    "        q = make_cross_for_query(df, q, \"wine_type\", \"cuisine\", \"wine_cuisine_cross_id\")\n",
    "\n",
    "    if \"wine_type\" in df.columns and \"food_category\" in df.columns:\n",
    "        q = make_cross_for_query(df, q, \"wine_type\", \"food_category\", \"wine_foodcat_cross_id\")\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 4: Predict scores\n",
    "    # ----------------------------------------------\n",
    "    Xq = q[feature_cols]\n",
    "    q[\"pred_scaled\"] = model.predict(Xq)\n",
    "    q[\"pred_score\"] = q[\"pred_scaled\"] * (max_r - min_r) + min_r\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 5: Use real dataset score if available\n",
    "    # ----------------------------------------------\n",
    "    merged = q.merge(\n",
    "        df[group_cols + [target_col]],\n",
    "        on=group_cols,\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged[\"final_score\"] = merged[target_col].fillna(merged[\"pred_score\"])\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # Step 6: Return Top-5 (no pred_score displayed)\n",
    "    # ----------------------------------------------\n",
    "    top5 = (\n",
    "        merged[[\"wine_type\", \"wine_category\", \"final_score\"]]\n",
    "        .sort_values(\"final_score\", ascending=False)\n",
    "        .head(5)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40936a48-f4c1-4a8d-a54e-f2e669477b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
